{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V100"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"hlzal3OPBj8T"},"outputs":[],"source":["! pip install transformers datasets py7zr evaluate rouge_score"]},{"cell_type":"code","source":["from random import randrange\n","\n","from datasets import load_dataset, concatenate_datasets\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\n","from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n","from transformers import pipeline\n","import evaluate\n","import nltk\n","import numpy as np\n","from nltk.tokenize import sent_tokenize\n","nltk.download(\"punkt\")"],"metadata":{"id":"DcB59-tJDQQr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dataset"],"metadata":{"id":"1xxGzymLDR5N"}},{"cell_type":"markdown","source":["We are going to fine-tune the [Flan-T5](https://huggingface.co/google/flan-t5-small) model to summarize dialogue/ chat threads similar to what is done in the ChatGPT interface. We will use the [SAMSum](https://huggingface.co/datasets/samsum) dataset. The SAMSum dataset contains about 16k messenger-like conversations with summaries. Conversations were created and written down by linguists fluent in English.\n","\n","(Thanks to [Philipp Schmid](https://www.philschmid.de/) for great examples of this task that were adapted for this notebook)"],"metadata":{"id":"_Dans9qkH9IF"}},{"cell_type":"code","source":["dataset = load_dataset(\"samsum\")\n","\n","print(f\"Train dataset size: {len(dataset['train'])}\")\n","print(f\"Test dataset size: {len(dataset['test'])}\")"],"metadata":{"id":"Rb8Uzi1ODSgl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset['train'][0]"],"metadata":{"id":"MuhhWXEbDfxs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Pre-process data"],"metadata":{"id":"t_nKBP9yD3i4"}},{"cell_type":"code","source":["# We will use the Flan T5 tokenizer to help us pre-process the data.\n","model_id=\"google/flan-t5-small\"\n","\n","# Load tokenizer of Flan-T5\n","tokenizer = AutoTokenizer.from_pretrained(model_id)"],"metadata":{"id":"GMWk36xeDuaZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# The maximum total input sequence length after tokenization.\n","# Sequences longer than this will be truncated, sequences shorter will be padded.\n","tokenized_inputs = concatenate_datasets([\n","    dataset[\"train\"], \n","    dataset[\"test\"]]).map(lambda x: tokenizer(x[\"dialogue\"], truncation=True), \n","    batched=True, \n","    remove_columns=[\"dialogue\", \"summary\"])\n","max_source_length = max([len(x) for x in tokenized_inputs[\"input_ids\"]])\n","print(f\"Max source length: {max_source_length}\")\n","\n","# The maximum total sequence length for target text after tokenization.\n","# Sequences longer than this will be truncated, sequences shorter will be padded.\"\n","tokenized_targets = concatenate_datasets([\n","    dataset[\"train\"], \n","    dataset[\"test\"]]).map(lambda x: tokenizer(x[\"summary\"], truncation=True), \n","    batched=True, \n","    remove_columns=[\"dialogue\", \"summary\"])\n","max_target_length = max([len(x) for x in tokenized_targets[\"input_ids\"]])\n","print(f\"Max target length: {max_target_length}\")"],"metadata":{"id":"Sf0CeMm-EJKD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def preprocess_function(sample,padding=\"max_length\"):\n","\n","    # Add prefix to the input prompt for t5\n","    inputs = [\"summarize: \" + item for item in sample[\"dialogue\"]]\n","\n","    # tokenize inputs\n","    model_inputs = tokenizer(inputs, max_length=max_source_length, \n","                             padding=padding, truncation=True)\n","\n","    # Tokenize targets with the `text_target` keyword argument\n","    labels = tokenizer(text_target=sample[\"summary\"], \n","                       max_length=max_target_length, padding=padding, \n","                       truncation=True)\n","\n","    # If we are padding here, replace all tokenizer.pad_token_id in the labels \n","    # by -100 when we want to ignore padding in the loss.\n","    if padding == \"max_length\":\n","        labels[\"input_ids\"] = [\n","            [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n","        ]\n","\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs"],"metadata":{"id":"gQfgzFk_EeLv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenized_dataset = dataset.map(preprocess_function, batched=True, \n","                                remove_columns=[\"dialogue\", \"summary\", \"id\"])\n","print(f\"Keys of tokenized dataset: {list(tokenized_dataset['train'].features)}\")"],"metadata":{"id":"O97GyjqkEkh-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Base/ Foundation Model"],"metadata":{"id":"WSRhhX3UEulI"}},{"cell_type":"code","source":["# load model from the hub\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_id)"],"metadata":{"id":"NuXzlS31Eqzx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Fine-tune"],"metadata":{"id":"OPhPXIW-E9A-"}},{"cell_type":"code","source":["# We will use the Rouge metric for evaluations. ROUGE, or Recall-Oriented \n","# Understudy for Gisting Evaluation, is a set of metrics and a software package \n","# used for evaluating automatic summarization and machine translation software \n","# in natural language processing. The metrics compare an automatically produced \n","# summary or translation against a reference or a set of references \n","# (human-produced) summary or translation.\n","metric = evaluate.load(\"rouge\")\n","\n","# helper function to postprocess text\n","def postprocess_text(preds, labels):\n","\n","    preds = [pred.strip() for pred in preds]\n","    labels = [label.strip() for label in labels]\n","\n","    # rougeLSum expects newline after each sentence\n","    preds = [\"\\n\".join(sent_tokenize(pred)) for pred in preds]\n","    labels = [\"\\n\".join(sent_tokenize(label)) for label in labels]\n","\n","    return preds, labels\n","\n","def compute_metrics(eval_preds):\n","\n","    preds, labels = eval_preds\n","    if isinstance(preds, tuple):\n","        preds = preds[0]\n","    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n","\n","    # Replace -100 in the labels as we can't decode them.\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","    # Some simple post-processing\n","    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n","\n","    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n","    result = {k: round(v * 100, 4) for k, v in result.items()}\n","    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n","    result[\"gen_len\"] = np.mean(prediction_lens)\n","    return result"],"metadata":{"id":"DH8uuMkGExTa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# we want to ignore tokenizer pad token in the loss\n","label_pad_token_id = -100\n","\n","# Data collator\n","data_collator = DataCollatorForSeq2Seq(\n","    tokenizer,\n","    model=model,\n","    label_pad_token_id=label_pad_token_id,\n","    pad_to_multiple_of=8\n",")"],"metadata":{"id":"XjNpZy_4FGV0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define training args\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"flan-t5-samsum\",\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    predict_with_generate=True,\n","    fp16=False, # Overflows with fp16\n","    learning_rate=5e-5,\n","    num_train_epochs=5,\n","    # logging & evaluation strategies\n","    logging_dir=f\"flan-t5-samsum/logs\",\n","    logging_strategy=\"steps\",\n","    logging_steps=500,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    save_total_limit=2,\n","    load_best_model_at_end=True,\n",")\n","\n","# Create Trainer instance\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=tokenized_dataset[\"train\"],\n","    eval_dataset=tokenized_dataset[\"test\"],\n","    compute_metrics=compute_metrics,\n",")"],"metadata":{"id":"WC_bHKU-FXmM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Start training\n","trainer.train()"],"metadata":{"id":"Vm71hYakGE2I"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[" # Evaluate"],"metadata":{"id":"4gjBQxRwGQH2"}},{"cell_type":"code","source":["# Evaluate using the same trainer.\n","trainer.evaluate()"],"metadata":{"id":"rkInDV7wGWiw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Try it out!"],"metadata":{"id":"l_k7ZVoXG59v"}},{"cell_type":"code","source":["# load model and tokenizer from with pipeline\n","summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer, device=0)\n","\n","# select a random test sample\n","sample = dataset['test'][randrange(len(dataset[\"test\"]))]\n","print(f\"dialogue: \\n{sample['dialogue']}\\n---------------\")\n","print(f\"reference summary: \\n{sample['summary']}\\n---------------\")\n","\n","# summarize dialogue\n","result = summarizer(sample[\"dialogue\"])\n","\n","print(f\"flan-t5-base summary:\\n{result[0]['summary_text']}\")"],"metadata":{"id":"PunLv5Q-G7Jv"},"execution_count":null,"outputs":[]}]}