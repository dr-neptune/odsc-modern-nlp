{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO3eeNyI1h9J0H6IfMnh2Ms"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["To run any prompt through a model, we need to set a foundation for how we will access generative AI models and perform inference. There is a huge variety in the landscape of generative AI models in terms of size, access patterns, licensing, etc. \n","\n","We will abstract away some of the model specificity using a tool called [Prediction Guard](https://www.predictionguard.com/). This tool wraps many state-of-the-art models under the hood to provide the best developer experience (without you having to worry about which model to call). *Prediction Guard* additionally gives you the convenience of automated model selection and future proofing through automatic model updates (without you having to update your implementation). \n","\n","To run your first LLM prompt with *Prediction Guard*:\n","\n","1. Sign up for an account on the [Prediction Guard website](https://www.predictionguard.com/). There is a 10 day free trial where you won't have to pay infrastructure and inference costs. \n","2. Create an access token on your account page\n","\n","Once you have that, you are ready to make your first LLM prompt below."],"metadata":{"id":"tx0f1rKRWqS_"}},{"cell_type":"markdown","source":["# Install dependences, imports"],"metadata":{"id":"ZGe8RF_LzKjK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"pI0jTm47xNj5"},"outputs":[],"source":["! pip install predictionguard"]},{"cell_type":"code","source":["import predictionguard as pg"],"metadata":{"id":"Wg7xvnBhxb38"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Create a client and generate some text"],"metadata":{"id":"fr7dHK-VyW2s"}},{"cell_type":"code","source":["client = pg.Client(token=\"<your access token>\")"],"metadata":{"id":"DGQwJv2lyWGg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["response = client.predict(name=\"default-text-gen\", data={\n","    \"prompt\": \"Tell me a joke\"\n","})\n","response"],"metadata":{"id":"9xw7U9qDzPKZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(response['text'])"],"metadata":{"id":"Hi0jZOzXXRP-"},"execution_count":null,"outputs":[]}]}