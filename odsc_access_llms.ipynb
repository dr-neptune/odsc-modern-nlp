{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPoKCPdf26QulBs2HN3Ol6V"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["To run any prompt through a model, we need to set a foundation for how we will access generative AI models and perform inference. There is a huge variety in the landscape of generative AI models in terms of size, access patterns, licensing, etc.\n","\n","We will use a tool called [Prediction Guard](https://www.predictionguard.com/) to call both proprietary models (like OpenAI) and open access LLMs (like Falcon, MPT, etc.) via a standardized OpenAI-like API. This will allow us to explore the full range of LLMs available. Further, it will illustrate how companies that are hesitant to send data to black box APIs (like OpenAI) can still integrate state-of-the-art generative text models.\n","\n","If you are interested, Prediction Guard does provide some significant functionality on top of this standardized API (see the [docs](https://docs.predictionguard.com/)). Specifically, it lets you:\n","\n","- **Control** the structure of and easily constrain LLM output to the types, formats, and information relevant to your business;\n","- **Validate** and check LLM output to guard against hallucination; and\n","- **Implement compliant LLM systems** (SOC 2, HIPAA, and self-hosted) that give your legal counsel warm fuzzy feeling while still delighting your customers with AI features.\n","\n","To run your first LLM prompt with *Prediction Guard*'s free trial:\n","\n","1. Sign up for an account on the [Prediction Guard website](https://www.predictionguard.com/). There is a 10 day free trial where you won't have to pay infrastructure and inference costs.\n","2. Create an access token on your Prediction Guard account page. Save or copy this token as you will need it below.\n","3. (Optional) Create an OpenAI account if you don't have one yet and you want to try out some of the functionality presented here with OpenAI's models. You will need your OpenAI API key to enable this functionality.\n","\n","Once you have completed the above steps, you are ready to make your first LLM prompt below."],"metadata":{"id":"tx0f1rKRWqS_"}},{"cell_type":"markdown","source":["# Install dependences, imports"],"metadata":{"id":"ZGe8RF_LzKjK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"pI0jTm47xNj5"},"outputs":[],"source":["! pip install predictionguard"]},{"cell_type":"code","source":["import os\n","\n","import predictionguard as pg\n","from getpass import getpass"],"metadata":{"id":"Wg7xvnBhxb38"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pg_access_token = getpass('Enter your Prediction Guard access token: ')\n","os.environ['PREDICTIONGUARD_TOKEN'] = pg_access_token"],"metadata":{"id":"K_cUA6tClxcM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# List available models"],"metadata":{"id":"eutZBE8vtLC5"}},{"cell_type":"markdown","source":["You can find out more about the models available via the Prediction Guard API [in the docs](https://docs.predictionguard.com/models)."],"metadata":{"id":"obLO0rEGtPTE"}},{"cell_type":"code","source":["pg.Completion.list_models()"],"metadata":{"id":"wM5pESLxtXic"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Generate some text from the latest open access LLMs"],"metadata":{"id":"fr7dHK-VyW2s"}},{"cell_type":"code","source":["response = pg.Completion.create(model=\"Falcon-7B-Instruct\",\n","                          prompt=\"Tell me a joke\")\n","response"],"metadata":{"id":"9xw7U9qDzPKZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(response['choices'][0]['text'])"],"metadata":{"id":"Hi0jZOzXXRP-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Generate text from a proprietary LLM (OpenAI)"],"metadata":{"id":"54ybrbDxnSi6"}},{"cell_type":"code","source":["openai_api_key = getpass('Enter your OpenAI API key: ')\n","os.environ['OPENAI_API_KEY'] = openai_api_key"],"metadata":{"id":"JadVmYcYnxj-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["response = pg.Completion.create(model=\"OpenAI-text-davinci-003\",\n","                          prompt=\"Tell me a joke\")\n","print(response['choices'][0]['text'])"],"metadata":{"id":"cwAXEVuHnVUx"},"execution_count":null,"outputs":[]}]}